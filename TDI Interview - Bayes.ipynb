{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian posterior inference: Explain Bayes’ Rule.  Write some code to actually perform posterior sampling.  Work out an example using conjugate priors.  How does this compare with hypothesis testing?  What are the underlying assumptions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing packages into 'C:/Users/Natalie/Documents/R/win-library/3.4'\n",
      "(as 'lib' is unspecified)\n",
      "Warning message:\n",
      "\"packages 'ggplot2', 'VennDiagram' are in use and will not be installed\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "package 'dplyr' successfully unpacked and MD5 sums checked\n",
      "package 'sciplot' successfully unpacked and MD5 sums checked\n",
      "package 'repr' successfully unpacked and MD5 sums checked\n",
      "\n",
      "The downloaded binary packages are in\n",
      "\tC:\\Users\\Natalie\\AppData\\Local\\Temp\\RtmpeEOg5J\\downloaded_packages\n"
     ]
    }
   ],
   "source": [
    "options(repos = c('https://cloud.r-project.org/'))\n",
    "install.packages(c(\"ggplot2\", \"dplyr\", \"sciplot\", \"repr\", \"VennDiagram\"))\n",
    "library(\"ggplot2\")\n",
    "library(\"VennDiagram\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have you ever wondered how likely something is given another event occured? Perhaps you're wondering how likely we are to see more manufacturing jobs in the US, $\\textit{given}$ Donald Trump is president. Or how likely the Winnipeg Jets are to win the Stanley Cup, $\\textit{given}$ their star player is hurt?\n",
    "\n",
    "If questions like these cross your mind, you may need a tool to determine the probability of one event given the other event occured. This is $\\textbf{Bayes' Rule}$ of conditional probability!\n",
    "\n",
    "The probability that the Jets win, given their star is hurt is the overlapping area in the venn diagram (purple) below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(polygon[GRID.polygon.28], polygon[GRID.polygon.29], polygon[GRID.polygon.30], polygon[GRID.polygon.31], text[GRID.text.32], text[GRID.text.33], text[GRID.text.34], text[GRID.text.35], text[GRID.text.36]) "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAGkCAMAAADewwbdAAAAn1BMVEUAAAAmJk00NGg6EyY+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\nATtPwM4TsPME7DwBO0/AzhOw8wTsvP8DiEHcpeL8pV8AAAAASUVORK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "options(repr.plot.width=4, repr.plot.height=3.5)\n",
    "draw.pairwise.venn(15, 15, 5, category = c(\"Jets Win\", \"Star hurt\"), lty = rep(\"blank\", \n",
    "2), fill = c(\"blue\", \"red\"), alpha = rep(0.5, 2), cat.pos = c(0, \n",
    " 0), cat.dist = rep(0.025, 2), scaled = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly the probability of the Jets winning is greater when their star is $\\textit{not}$ hurt, as the blue circle area (not includuing the purple overlap area) is much larger than the middle of the venn diagram where both the Jets win and the Star is hurt.\n",
    "\n",
    "A = probability of Jets winning\n",
    "\n",
    "B = probability star is hurt\n",
    "\n",
    "In probability, this is expressed as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P(A|B) = \\frac{P(A\\cap B)}{P(B)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probability of A (Jets win) Given (|) B (star is hurt) = the probability of A and B both occuring, divided by the probability of B occuring. We know intuitively that the probability of 2 things happening together is lower than 1 thing happening on it's own. This is Bayes' Rule, you are trying to determine how likely event 'A' is given that B already happened. \n",
    "\n",
    "$P(A\\cap B) = P(B|A) P(A) $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This same formula can be written as:\n",
    "\n",
    "$P(A|B) = \\frac{P(B|A) P(A)}{P(B)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try this hockey example out, we know the Jets have a high chance of winning at 60%, and the liklihood of getting hurt on the ice is 20%. The chances of them winning decrease by 20% if the star is hurt. If you heard the Jets won the Stanley Cup, what is the probability their star was hurt?\n",
    "\n",
    "\n",
    "P(Win) = 0.60\n",
    "\n",
    "P(Hurt) = 0.20\n",
    "\n",
    "P(win|Hurt) = 0.40\n",
    "\n",
    "P(Hurt|Win) = ?\n",
    "\n",
    "\n",
    "$P(Hurt|Win) = \\frac{P(Hhurt) P(Win|Hurt)}{P(Win)}$\n",
    "\n",
    "$P(Hurt|Win) = \\frac{0.2* 0.4}{0.6}$ = 0.133 = 13%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the basic concept of Bayes' Theorem. But what if you have probabilities of events occuring based on 1 set of data, and then later you collect more data and this value changes? Wouldn't it be great if we could update our probabilities with the new data?  This is possible with posterior sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### It turns out Bayes' Theorem is often expressed in terms of 'priors' and 'posteriors'.\n",
    "\n",
    "Given a prior hypothesis $\\textbf{H}$, and some posterior evidence $\\textbf{E}$, the probabilty of the hypothesis prior to any evidence $\\textbf{P(H)}$, and the posterior probability of the hypothesis after collecting evidence $\\textbf{P(H|E)}$\n",
    "\n",
    "$P(H|E) = \\frac{P(E|H) P(H)}{P(E)}$ \n",
    "= $\\frac{P(B|A) P(A)}{P(B|A)P(A) + P(B|A*)P(A*)}$\n",
    "\n",
    "$P(H)$ = Prior Probability\n",
    "\n",
    "$P(H|E)$ = Posterior probability\n",
    "\n",
    "$\\frac{P(E|H)} {P(E)}$ = Liklihood Ratio\n",
    "\n",
    "\n",
    "\n",
    "Bayes' Theorem now becomes: the posterior probability equals the prior probability multiplied by the liklihood ratio.\n",
    "\n",
    "This is particularily useful when you are training models to get better over time, or update values based on some conditions. For example, Amazon may suggest products to you given your previous purchases. As you make more purchases, the ability to predict what you may like increases.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're interested in these types of problems, numerical solutions can be pretty tough! \n",
    "##### Luckily, we can approximate the posterior distribution with a Marcov-chain Monte-Carlo (MCMC) simulation.\n",
    "\n",
    "A Marcov-chain is a mathamatical system that represents the possible states of a system. For example, a person may have the states \"sleeping\", \"eating\", or \"working\". The Marcov chain will predict which state the person will move to nexted based soley on the current state. This is said to have no memory. The probability of transitioning from state to state is also recorded.\n",
    "\n",
    "used to select the next location based on the current location, and has no memory of previous locations.\n",
    "$P(next location) = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Monte Carlo simulation works by allowing a paramater to vary about a distribution (i.e., normal, logistic etc.) and creates many, many results based on these range of values. Thereby the simulation creates a range of results. If the distribution is normal, the results will tend to center around the mean\n",
    "\n",
    "building models of possible results by substituting a range of values—a probability distribution—for any factor that has inherent uncertainty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posterior estimation is proporational to prior and liklihood. Sum up all prior*liklihoods then divide all individual prior*liklihood values by this sum to normalize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "posterior distribution is from same distribution as prior"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
