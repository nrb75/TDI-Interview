{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "want to know avg # of ppl to come to concert\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing packages into 'C:/Users/nrb75/Documents/R/win-library/3.4'\n",
      "(as 'lib' is unspecified)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "package 'ggplot2' successfully unpacked and MD5 sums checked\n",
      "package 'dplyr' successfully unpacked and MD5 sums checked\n",
      "package 'sciplot' successfully unpacked and MD5 sums checked\n",
      "package 'reshape' successfully unpacked and MD5 sums checked\n",
      "package 'TeachBayes' successfully unpacked and MD5 sums checked\n",
      "\n",
      "The downloaded binary packages are in\n",
      "\tC:\\Users\\nrb75\\AppData\\Local\\Temp\\RtmpuQfqZW\\downloaded_packages\n"
     ]
    }
   ],
   "source": [
    "options(repos = c('https://cloud.r-project.org/'))\n",
    "options(digits=3)\n",
    "install.packages(c(\"ggplot2\", \"dplyr\", \"sciplot\", \"reshape\", \"TeachBayes\"))\n",
    "#library(sciPlot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Model</th><th scope=col>Prior</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td> 3   </td><td>0.067</td></tr>\n",
       "\t<tr><td> 4   </td><td>0.067</td></tr>\n",
       "\t<tr><td> 5   </td><td>0.067</td></tr>\n",
       "\t<tr><td> 6   </td><td>0.067</td></tr>\n",
       "\t<tr><td> 7   </td><td>0.067</td></tr>\n",
       "\t<tr><td> 8   </td><td>0.067</td></tr>\n",
       "\t<tr><td> 9   </td><td>0.067</td></tr>\n",
       "\t<tr><td>10   </td><td>0.067</td></tr>\n",
       "\t<tr><td>11   </td><td>0.067</td></tr>\n",
       "\t<tr><td>12   </td><td>0.067</td></tr>\n",
       "\t<tr><td>13   </td><td>0.067</td></tr>\n",
       "\t<tr><td>14   </td><td>0.067</td></tr>\n",
       "\t<tr><td>15   </td><td>0.067</td></tr>\n",
       "\t<tr><td>16   </td><td>0.067</td></tr>\n",
       "\t<tr><td>17   </td><td>0.067</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       " Model & Prior\\\\\n",
       "\\hline\n",
       "\t  3    & 0.067\\\\\n",
       "\t  4    & 0.067\\\\\n",
       "\t  5    & 0.067\\\\\n",
       "\t  6    & 0.067\\\\\n",
       "\t  7    & 0.067\\\\\n",
       "\t  8    & 0.067\\\\\n",
       "\t  9    & 0.067\\\\\n",
       "\t 10    & 0.067\\\\\n",
       "\t 11    & 0.067\\\\\n",
       "\t 12    & 0.067\\\\\n",
       "\t 13    & 0.067\\\\\n",
       "\t 14    & 0.067\\\\\n",
       "\t 15    & 0.067\\\\\n",
       "\t 16    & 0.067\\\\\n",
       "\t 17    & 0.067\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "Model | Prior | \n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "|  3    | 0.067 | \n",
       "|  4    | 0.067 | \n",
       "|  5    | 0.067 | \n",
       "|  6    | 0.067 | \n",
       "|  7    | 0.067 | \n",
       "|  8    | 0.067 | \n",
       "|  9    | 0.067 | \n",
       "| 10    | 0.067 | \n",
       "| 11    | 0.067 | \n",
       "| 12    | 0.067 | \n",
       "| 13    | 0.067 | \n",
       "| 14    | 0.067 | \n",
       "| 15    | 0.067 | \n",
       "| 16    | 0.067 | \n",
       "| 17    | 0.067 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "   Model Prior\n",
       "1   3    0.067\n",
       "2   4    0.067\n",
       "3   5    0.067\n",
       "4   6    0.067\n",
       "5   7    0.067\n",
       "6   8    0.067\n",
       "7   9    0.067\n",
       "8  10    0.067\n",
       "9  11    0.067\n",
       "10 12    0.067\n",
       "11 13    0.067\n",
       "12 14    0.067\n",
       "13 15    0.067\n",
       "14 16    0.067\n",
       "15 17    0.067"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "size=sort(c(5,8,3,12,10,8,6,17,11,5,9,10,12,6))\n",
    "Model=seq(3,17,1) #want to determine which model is most likely, i.e., which crowd size is most likely\n",
    "Prior=round(rep(1/15, 15),3)\n",
    "ybar=mean(size)\n",
    "sd_size=sd(size)\n",
    "\n",
    "df_size=data.frame(Model, Prior)\n",
    "df_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Create Likelihood that each model (crowd size) is true, given the observed collected data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Model</th><th scope=col>Prior</th><th scope=col>Likelihood</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td> 3     </td><td>0.067  </td><td>0.03231</td></tr>\n",
       "\t<tr><td> 4     </td><td>0.067  </td><td>0.04762</td></tr>\n",
       "\t<tr><td> 5     </td><td>0.067  </td><td>0.06514</td></tr>\n",
       "\t<tr><td> 6     </td><td>0.067  </td><td>0.08272</td></tr>\n",
       "\t<tr><td> 7     </td><td>0.067  </td><td>0.09752</td></tr>\n",
       "\t<tr><td> 8     </td><td>0.067  </td><td>0.10673</td></tr>\n",
       "\t<tr><td> 9     </td><td>0.067  </td><td>0.10845</td></tr>\n",
       "\t<tr><td>10     </td><td>0.067  </td><td>0.10229</td></tr>\n",
       "\t<tr><td>11     </td><td>0.067  </td><td>0.08958</td></tr>\n",
       "\t<tr><td>12     </td><td>0.067  </td><td>0.07282</td></tr>\n",
       "\t<tr><td>13     </td><td>0.067  </td><td>0.05496</td></tr>\n",
       "\t<tr><td>14     </td><td>0.067  </td><td>0.03850</td></tr>\n",
       "\t<tr><td>15     </td><td>0.067  </td><td>0.02504</td></tr>\n",
       "\t<tr><td>16     </td><td>0.067  </td><td>0.01512</td></tr>\n",
       "\t<tr><td>17     </td><td>0.067  </td><td>0.00848</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lll}\n",
       " Model & Prior & Likelihood\\\\\n",
       "\\hline\n",
       "\t  3      & 0.067   & 0.03231\\\\\n",
       "\t  4      & 0.067   & 0.04762\\\\\n",
       "\t  5      & 0.067   & 0.06514\\\\\n",
       "\t  6      & 0.067   & 0.08272\\\\\n",
       "\t  7      & 0.067   & 0.09752\\\\\n",
       "\t  8      & 0.067   & 0.10673\\\\\n",
       "\t  9      & 0.067   & 0.10845\\\\\n",
       "\t 10      & 0.067   & 0.10229\\\\\n",
       "\t 11      & 0.067   & 0.08958\\\\\n",
       "\t 12      & 0.067   & 0.07282\\\\\n",
       "\t 13      & 0.067   & 0.05496\\\\\n",
       "\t 14      & 0.067   & 0.03850\\\\\n",
       "\t 15      & 0.067   & 0.02504\\\\\n",
       "\t 16      & 0.067   & 0.01512\\\\\n",
       "\t 17      & 0.067   & 0.00848\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "Model | Prior | Likelihood | \n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "|  3      | 0.067   | 0.03231 | \n",
       "|  4      | 0.067   | 0.04762 | \n",
       "|  5      | 0.067   | 0.06514 | \n",
       "|  6      | 0.067   | 0.08272 | \n",
       "|  7      | 0.067   | 0.09752 | \n",
       "|  8      | 0.067   | 0.10673 | \n",
       "|  9      | 0.067   | 0.10845 | \n",
       "| 10      | 0.067   | 0.10229 | \n",
       "| 11      | 0.067   | 0.08958 | \n",
       "| 12      | 0.067   | 0.07282 | \n",
       "| 13      | 0.067   | 0.05496 | \n",
       "| 14      | 0.067   | 0.03850 | \n",
       "| 15      | 0.067   | 0.02504 | \n",
       "| 16      | 0.067   | 0.01512 | \n",
       "| 17      | 0.067   | 0.00848 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "   Model Prior Likelihood\n",
       "1   3    0.067 0.03231   \n",
       "2   4    0.067 0.04762   \n",
       "3   5    0.067 0.06514   \n",
       "4   6    0.067 0.08272   \n",
       "5   7    0.067 0.09752   \n",
       "6   8    0.067 0.10673   \n",
       "7   9    0.067 0.10845   \n",
       "8  10    0.067 0.10229   \n",
       "9  11    0.067 0.08958   \n",
       "10 12    0.067 0.07282   \n",
       "11 13    0.067 0.05496   \n",
       "12 14    0.067 0.03850   \n",
       "13 15    0.067 0.02504   \n",
       "14 16    0.067 0.01512   \n",
       "15 17    0.067 0.00848   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_size$Likelihood=dnorm(ybar, mean=Model, sd=sd_size) #dnorm is a density function that calculates the relative likelihood that the value of the random variable would equal that sample. \n",
    "#Likelihood is calculated based on a normal distribution with the observed Models serving as possible means, and standard deviation is the observed sd\n",
    "#here the density, or probability of observing that point, for the observed average (ybar) is calculated for a normal distribution with each of the Model means.\n",
    "\n",
    "df_size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the Posterior distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Model</th><th scope=col>Prior</th><th scope=col>Likelihood</th><th scope=col>Product</th><th scope=col>Posterior</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td> 3      </td><td>0.067   </td><td>0.03231 </td><td>0.002165</td><td>0.03411 </td></tr>\n",
       "\t<tr><td> 4      </td><td>0.067   </td><td>0.04762 </td><td>0.003190</td><td>0.05027 </td></tr>\n",
       "\t<tr><td> 5      </td><td>0.067   </td><td>0.06514 </td><td>0.004364</td><td>0.06876 </td></tr>\n",
       "\t<tr><td> 6      </td><td>0.067   </td><td>0.08272 </td><td>0.005542</td><td>0.08732 </td></tr>\n",
       "\t<tr><td> 7      </td><td>0.067   </td><td>0.09752 </td><td>0.006534</td><td>0.10295 </td></tr>\n",
       "\t<tr><td> 8      </td><td>0.067   </td><td>0.10673 </td><td>0.007151</td><td>0.11267 </td></tr>\n",
       "\t<tr><td> 9      </td><td>0.067   </td><td>0.10845 </td><td>0.007266</td><td>0.11448 </td></tr>\n",
       "\t<tr><td>10      </td><td>0.067   </td><td>0.10229 </td><td>0.006854</td><td>0.10799 </td></tr>\n",
       "\t<tr><td>11      </td><td>0.067   </td><td>0.08958 </td><td>0.006002</td><td>0.09456 </td></tr>\n",
       "\t<tr><td>12      </td><td>0.067   </td><td>0.07282 </td><td>0.004879</td><td>0.07687 </td></tr>\n",
       "\t<tr><td>13      </td><td>0.067   </td><td>0.05496 </td><td>0.003682</td><td>0.05801 </td></tr>\n",
       "\t<tr><td>14      </td><td>0.067   </td><td>0.03850 </td><td>0.002580</td><td>0.04065 </td></tr>\n",
       "\t<tr><td>15      </td><td>0.067   </td><td>0.02504 </td><td>0.001678</td><td>0.02644 </td></tr>\n",
       "\t<tr><td>16      </td><td>0.067   </td><td>0.01512 </td><td>0.001013</td><td>0.01596 </td></tr>\n",
       "\t<tr><td>17      </td><td>0.067   </td><td>0.00848 </td><td>0.000568</td><td>0.00895 </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllll}\n",
       " Model & Prior & Likelihood & Product & Posterior\\\\\n",
       "\\hline\n",
       "\t  3       & 0.067    & 0.03231  & 0.002165 & 0.03411 \\\\\n",
       "\t  4       & 0.067    & 0.04762  & 0.003190 & 0.05027 \\\\\n",
       "\t  5       & 0.067    & 0.06514  & 0.004364 & 0.06876 \\\\\n",
       "\t  6       & 0.067    & 0.08272  & 0.005542 & 0.08732 \\\\\n",
       "\t  7       & 0.067    & 0.09752  & 0.006534 & 0.10295 \\\\\n",
       "\t  8       & 0.067    & 0.10673  & 0.007151 & 0.11267 \\\\\n",
       "\t  9       & 0.067    & 0.10845  & 0.007266 & 0.11448 \\\\\n",
       "\t 10       & 0.067    & 0.10229  & 0.006854 & 0.10799 \\\\\n",
       "\t 11       & 0.067    & 0.08958  & 0.006002 & 0.09456 \\\\\n",
       "\t 12       & 0.067    & 0.07282  & 0.004879 & 0.07687 \\\\\n",
       "\t 13       & 0.067    & 0.05496  & 0.003682 & 0.05801 \\\\\n",
       "\t 14       & 0.067    & 0.03850  & 0.002580 & 0.04065 \\\\\n",
       "\t 15       & 0.067    & 0.02504  & 0.001678 & 0.02644 \\\\\n",
       "\t 16       & 0.067    & 0.01512  & 0.001013 & 0.01596 \\\\\n",
       "\t 17       & 0.067    & 0.00848  & 0.000568 & 0.00895 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "Model | Prior | Likelihood | Product | Posterior | \n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "|  3       | 0.067    | 0.03231  | 0.002165 | 0.03411  | \n",
       "|  4       | 0.067    | 0.04762  | 0.003190 | 0.05027  | \n",
       "|  5       | 0.067    | 0.06514  | 0.004364 | 0.06876  | \n",
       "|  6       | 0.067    | 0.08272  | 0.005542 | 0.08732  | \n",
       "|  7       | 0.067    | 0.09752  | 0.006534 | 0.10295  | \n",
       "|  8       | 0.067    | 0.10673  | 0.007151 | 0.11267  | \n",
       "|  9       | 0.067    | 0.10845  | 0.007266 | 0.11448  | \n",
       "| 10       | 0.067    | 0.10229  | 0.006854 | 0.10799  | \n",
       "| 11       | 0.067    | 0.08958  | 0.006002 | 0.09456  | \n",
       "| 12       | 0.067    | 0.07282  | 0.004879 | 0.07687  | \n",
       "| 13       | 0.067    | 0.05496  | 0.003682 | 0.05801  | \n",
       "| 14       | 0.067    | 0.03850  | 0.002580 | 0.04065  | \n",
       "| 15       | 0.067    | 0.02504  | 0.001678 | 0.02644  | \n",
       "| 16       | 0.067    | 0.01512  | 0.001013 | 0.01596  | \n",
       "| 17       | 0.067    | 0.00848  | 0.000568 | 0.00895  | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "   Model Prior Likelihood Product  Posterior\n",
       "1   3    0.067 0.03231    0.002165 0.03411  \n",
       "2   4    0.067 0.04762    0.003190 0.05027  \n",
       "3   5    0.067 0.06514    0.004364 0.06876  \n",
       "4   6    0.067 0.08272    0.005542 0.08732  \n",
       "5   7    0.067 0.09752    0.006534 0.10295  \n",
       "6   8    0.067 0.10673    0.007151 0.11267  \n",
       "7   9    0.067 0.10845    0.007266 0.11448  \n",
       "8  10    0.067 0.10229    0.006854 0.10799  \n",
       "9  11    0.067 0.08958    0.006002 0.09456  \n",
       "10 12    0.067 0.07282    0.004879 0.07687  \n",
       "11 13    0.067 0.05496    0.003682 0.05801  \n",
       "12 14    0.067 0.03850    0.002580 0.04065  \n",
       "13 15    0.067 0.02504    0.001678 0.02644  \n",
       "14 16    0.067 0.01512    0.001013 0.01596  \n",
       "15 17    0.067 0.00848    0.000568 0.00895  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_size$Product = df_size$Prior* df_size$Likelihood\n",
    "df_size$Posterior=df_size$Product/sum(df_size$Product)\n",
    "df_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good check is that the sum of the Posterior probabilities = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "1"
      ],
      "text/latex": [
       "1"
      ],
      "text/markdown": [
       "1"
      ],
      "text/plain": [
       "[1] 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sum(df_size$Posterior)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good, the sum of the posterior probabilities = 1, as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the probability density plot to see how likely crowd sizes are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhwAAAIcCAMAAACKIIdOAAAAY1BMVEUAAAAzMzNDbu5NTU1o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\n5X/xQE04UVf4QwAAAABJRU5ErkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "options(repr.plot.width=4.5, repr.plot.height=4.5)\n",
    "library(reshape)\n",
    "library(ggplot2)\n",
    "\n",
    "df.long=melt(df_size, id=\"Model\")\n",
    "\n",
    "plt.std=plt.std=theme(legend.position=\"top\", legend.text = element_text(size=12), axis.text.x = element_text(size=12),  axis.text.y = element_text(size=12), axis.title.y = element_text(size=14), strip.text.x = element_text(size=16), panel.background = element_rect(fill='white', colour='black'), legend.key = element_blank())\n",
    "color1=c(\"royalblue2\", \"red2\")\n",
    "ggplot(data=subset(df.long, variable%in% c(\"Prior\", \"Posterior\")), aes(x=as.factor(Model), y=value, fill=variable))+geom_bar(stat=\"identity\", position=\"dodge\")+ylab(\"Probability\")+scale_fill_manual(values=color1, name=\"\")+xlab(\"Models of crowd size\")+ggtitle(\"Probabilities of crowd size\")+plt.std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
