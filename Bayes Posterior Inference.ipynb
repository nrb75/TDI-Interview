{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayesian posterior inference: Explain Bayesâ€™ Rule. Write some code to actually perform posterior sampling. Work out an example using conjugate priors. How does this compare with hypothesis testing? What are the underlying assumptions?\n",
    "\n",
    "### In many real world applications, we don't know the probability of events, but we would like to estimate this unknown probability based on our hypothesis and collected evidence. Seems rational, right? \n",
    "\n",
    "#### This is the basis for Bayes' Rule, where we:\n",
    "1. Identify possible models and construct prior probabilities (based on our knowledge or beliefs)\n",
    "2. Collect data and create liklihoods, or the chance of getting this data given each model \n",
    "3. Use Bayes' rule to find posterior probabilities and update our knowledge so we can determine which model is likely to be correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The basic conditional probability equation is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P(A|B) = \\frac{P(A\\cap B)}{P(B)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probability of A ${given}$ B is equal to the probability of both A and B occuring, normalized by the probability of B occuring. This is often written as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "$P(A|B) = \\frac{P(B|A) P(A)}{P(B)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we would say the Posterior probability P(A|B) is equal to the Likelihood P(B|A) multiplied by the Prior P(A) normalized by the probability of data P(B)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's work through an example and describe some of the particulars as we go.\n",
    "Say you're the city manager of Austin planning a free concert. Woah big city! And a heck of a music scene! This seems like a big task, and you want to know about how many people will come so you can plan ahead and order the right amount of food. You don't need an exact headcount because ordering is done in bulk. So you would like to know the approximate proportion of the city that will show up in 10% groups (10%, 20%, 30%, etc). Because you've been the city manager for a few years, you have some prior knowledge of these concerts and believe at least 20% of the town will show up, but not more than 90%. You also believe the 60% and 70% groups are 2X as likely as the others. What is the estimated proportion of the city that will show up? \n",
    "\n",
    "You're pretty savvy, and send out an email asking if people will attend the concert. You send it out to 150 people and 70 respond 'yes' and 80 respond 'no'. You know this proportion of attendance (70/150 = 0.46) is not the real estimate because surveys are not always accurate and people do change their minds. So, you want to employ some statistics to help you estimate the most likely proportion of people that will come.\n",
    "\n",
    "Let's define this problem in Bayes terms.\n",
    "\n",
    "#### 1. Identify possible models and construct prior probabilities\n",
    "\n",
    "The models are the proportion of the town that will show up. We want to estimate the probability that each 'model' is true so we can determine the most likely scenario. The models are: p=0.3, p=0.4, p=0.5, p=0.6, p=0.6, p=0.8 and p=0.9\n",
    "Prior probabilities are based on what we know about concert attendance. In this case, we have 7 models (p=0.3 ... p=0.9), if the probability of each model being true were equal the 'prior probabilities' would = 1/7. However, we know that p=0.6 is 2X as likely. The sum of prior probabilities must sum to 1. Therefore the model and priors are:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing packages into 'C:/Users/nrb75/Documents/R/win-library/3.4'\n",
      "(as 'lib' is unspecified)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "package 'ggplot2' successfully unpacked and MD5 sums checked\n",
      "package 'dplyr' successfully unpacked and MD5 sums checked\n",
      "package 'sciplot' successfully unpacked and MD5 sums checked\n",
      "package 'reshape' successfully unpacked and MD5 sums checked\n",
      "package 'TeachBayes' successfully unpacked and MD5 sums checked\n",
      "\n",
      "The downloaded binary packages are in\n",
      "\tC:\\Users\\nrb75\\AppData\\Local\\Temp\\RtmpCMHkN3\\downloaded_packages\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>Models</th><th scope=col>Priors</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>p=0.3</th><td>0.3 </td><td>0.12</td></tr>\n",
       "\t<tr><th scope=row>p=0.4</th><td>0.4 </td><td>0.12</td></tr>\n",
       "\t<tr><th scope=row>p=0.5</th><td>0.5 </td><td>0.12</td></tr>\n",
       "\t<tr><th scope=row>p=0.6</th><td>0.6 </td><td>0.25</td></tr>\n",
       "\t<tr><th scope=row>p=0.7</th><td>0.7 </td><td>0.12</td></tr>\n",
       "\t<tr><th scope=row>p=0.8</th><td>0.8 </td><td>0.12</td></tr>\n",
       "\t<tr><th scope=row>p=0.9</th><td>0.9 </td><td>0.12</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       "  & Models & Priors\\\\\n",
       "\\hline\n",
       "\tp=0.3 & 0.3  & 0.12\\\\\n",
       "\tp=0.4 & 0.4  & 0.12\\\\\n",
       "\tp=0.5 & 0.5  & 0.12\\\\\n",
       "\tp=0.6 & 0.6  & 0.25\\\\\n",
       "\tp=0.7 & 0.7  & 0.12\\\\\n",
       "\tp=0.8 & 0.8  & 0.12\\\\\n",
       "\tp=0.9 & 0.9  & 0.12\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | Models | Priors | \n",
       "|---|---|---|---|---|---|---|\n",
       "| p=0.3 | 0.3  | 0.12 | \n",
       "| p=0.4 | 0.4  | 0.12 | \n",
       "| p=0.5 | 0.5  | 0.12 | \n",
       "| p=0.6 | 0.6  | 0.25 | \n",
       "| p=0.7 | 0.7  | 0.12 | \n",
       "| p=0.8 | 0.8  | 0.12 | \n",
       "| p=0.9 | 0.9  | 0.12 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "      Models Priors\n",
       "p=0.3 0.3    0.12  \n",
       "p=0.4 0.4    0.12  \n",
       "p=0.5 0.5    0.12  \n",
       "p=0.6 0.6    0.25  \n",
       "p=0.7 0.7    0.12  \n",
       "p=0.8 0.8    0.12  \n",
       "p=0.9 0.9    0.12  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "options(repos = c('https://cloud.r-project.org/'))\n",
    "install.packages(c(\"ggplot2\", \"dplyr\", \"sciplot\", \"reshape\", \"TeachBayes\"))\n",
    "\n",
    "Models=c(0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9)\n",
    "Priors=round(c(1/8, 1/8, 1/8, 2/8, 1/8, 1/8, 1/8),2)\n",
    "\n",
    "df=data.frame(Models, Priors)\n",
    "rownames(df)=c(\"p=0.3\", \"p=0.4\", \"p=0.5\", \"p=0.6\", \"p=0.7\", \"p=0.8\", \"p=0.9\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Collect Data and create liklihoods\n",
    "\n",
    "A liklihood is the probability of observing your result ${given}$ the model is true. In this scenario, the observed result is that from the survey. This is a binomial function where Success is defined as 'yes' I will attend the concert. Success=70, size = 150, and binomial probability of succes = models. Now we simply calculate the liklihood of observing the survey results, ${given}$ the model is true.\n",
    "\n",
    "For example, the liklihood that p=0.3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "6.76225718888869e-06"
      ],
      "text/latex": [
       "6.76225718888869e-06"
      ],
      "text/markdown": [
       "6.76225718888869e-06"
      ],
      "text/plain": [
       "[1] 6.762257e-06"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dbinom(70, size=150, prob=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a very low value! and it suggests the liklihood of observing this survey result, ${given}$ the actual probability of attendance is 0.3 is very low.\n",
    "\n",
    "Calculating the liklihood for the remaining models given the survey data is true:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>Models</th><th scope=col>Priors</th><th scope=col>Liklihood</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>p=0.3</th><td>0.3         </td><td>0.12        </td><td>6.762257e-06</td></tr>\n",
       "\t<tr><th scope=row>p=0.4</th><td>0.4         </td><td>0.12        </td><td>1.659816e-02</td></tr>\n",
       "\t<tr><th scope=row>p=0.5</th><td>0.5         </td><td>0.12        </td><td>4.669402e-02</td></tr>\n",
       "\t<tr><th scope=row>p=0.6</th><td>0.6         </td><td>0.25        </td><td>2.878376e-04</td></tr>\n",
       "\t<tr><th scope=row>p=0.7</th><td>0.7         </td><td>0.12        </td><td>1.413591e-09</td></tr>\n",
       "\t<tr><th scope=row>p=0.8</th><td>0.8         </td><td>0.12        </td><td>1.325743e-19</td></tr>\n",
       "\t<tr><th scope=row>p=0.9</th><td>0.9         </td><td>0.12        </td><td>4.175768e-40</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lll}\n",
       "  & Models & Priors & Liklihood\\\\\n",
       "\\hline\n",
       "\tp=0.3 & 0.3          & 0.12         & 6.762257e-06\\\\\n",
       "\tp=0.4 & 0.4          & 0.12         & 1.659816e-02\\\\\n",
       "\tp=0.5 & 0.5          & 0.12         & 4.669402e-02\\\\\n",
       "\tp=0.6 & 0.6          & 0.25         & 2.878376e-04\\\\\n",
       "\tp=0.7 & 0.7          & 0.12         & 1.413591e-09\\\\\n",
       "\tp=0.8 & 0.8          & 0.12         & 1.325743e-19\\\\\n",
       "\tp=0.9 & 0.9          & 0.12         & 4.175768e-40\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | Models | Priors | Liklihood | \n",
       "|---|---|---|---|---|---|---|\n",
       "| p=0.3 | 0.3          | 0.12         | 6.762257e-06 | \n",
       "| p=0.4 | 0.4          | 0.12         | 1.659816e-02 | \n",
       "| p=0.5 | 0.5          | 0.12         | 4.669402e-02 | \n",
       "| p=0.6 | 0.6          | 0.25         | 2.878376e-04 | \n",
       "| p=0.7 | 0.7          | 0.12         | 1.413591e-09 | \n",
       "| p=0.8 | 0.8          | 0.12         | 1.325743e-19 | \n",
       "| p=0.9 | 0.9          | 0.12         | 4.175768e-40 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "      Models Priors Liklihood   \n",
       "p=0.3 0.3    0.12   6.762257e-06\n",
       "p=0.4 0.4    0.12   1.659816e-02\n",
       "p=0.5 0.5    0.12   4.669402e-02\n",
       "p=0.6 0.6    0.25   2.878376e-04\n",
       "p=0.7 0.7    0.12   1.413591e-09\n",
       "p=0.8 0.8    0.12   1.325743e-19\n",
       "p=0.9 0.9    0.12   4.175768e-40"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df$Liklihood=dbinom(70, size=150, prob=Models)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Now we want to update our prior probabilities with a posterior probability, which depends on our priors and the observed data.\n",
    "\n",
    "$Posterior\\ probability =\\frac{Prior\\ x\\ Liklihood} {\\sum(Prior\\ x\\ Liklihood)}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>Models</th><th scope=col>Priors</th><th scope=col>Liklihood</th><th scope=col>Product</th><th scope=col>Posterior</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>p=0.3</th><td>0.3         </td><td>0.12        </td><td>6.762257e-06</td><td>8.114709e-07</td><td>1.058279e-04</td></tr>\n",
       "\t<tr><th scope=row>p=0.4</th><td>0.4         </td><td>0.12        </td><td>1.659816e-02</td><td>1.991780e-03</td><td>2.597578e-01</td></tr>\n",
       "\t<tr><th scope=row>p=0.5</th><td>0.5         </td><td>0.12        </td><td>4.669402e-02</td><td>5.603283e-03</td><td>7.307517e-01</td></tr>\n",
       "\t<tr><th scope=row>p=0.6</th><td>0.6         </td><td>0.25        </td><td>2.878376e-04</td><td>7.195939e-05</td><td>9.384579e-03</td></tr>\n",
       "\t<tr><th scope=row>p=0.7</th><td>0.7         </td><td>0.12        </td><td>1.413591e-09</td><td>1.696309e-10</td><td>2.212241e-08</td></tr>\n",
       "\t<tr><th scope=row>p=0.8</th><td>0.8         </td><td>0.12        </td><td>1.325743e-19</td><td>1.590892e-20</td><td>2.074760e-18</td></tr>\n",
       "\t<tr><th scope=row>p=0.9</th><td>0.9         </td><td>0.12        </td><td>4.175768e-40</td><td>5.010921e-41</td><td>6.534989e-39</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllll}\n",
       "  & Models & Priors & Liklihood & Product & Posterior\\\\\n",
       "\\hline\n",
       "\tp=0.3 & 0.3          & 0.12         & 6.762257e-06 & 8.114709e-07 & 1.058279e-04\\\\\n",
       "\tp=0.4 & 0.4          & 0.12         & 1.659816e-02 & 1.991780e-03 & 2.597578e-01\\\\\n",
       "\tp=0.5 & 0.5          & 0.12         & 4.669402e-02 & 5.603283e-03 & 7.307517e-01\\\\\n",
       "\tp=0.6 & 0.6          & 0.25         & 2.878376e-04 & 7.195939e-05 & 9.384579e-03\\\\\n",
       "\tp=0.7 & 0.7          & 0.12         & 1.413591e-09 & 1.696309e-10 & 2.212241e-08\\\\\n",
       "\tp=0.8 & 0.8          & 0.12         & 1.325743e-19 & 1.590892e-20 & 2.074760e-18\\\\\n",
       "\tp=0.9 & 0.9          & 0.12         & 4.175768e-40 & 5.010921e-41 & 6.534989e-39\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | Models | Priors | Liklihood | Product | Posterior | \n",
       "|---|---|---|---|---|---|---|\n",
       "| p=0.3 | 0.3          | 0.12         | 6.762257e-06 | 8.114709e-07 | 1.058279e-04 | \n",
       "| p=0.4 | 0.4          | 0.12         | 1.659816e-02 | 1.991780e-03 | 2.597578e-01 | \n",
       "| p=0.5 | 0.5          | 0.12         | 4.669402e-02 | 5.603283e-03 | 7.307517e-01 | \n",
       "| p=0.6 | 0.6          | 0.25         | 2.878376e-04 | 7.195939e-05 | 9.384579e-03 | \n",
       "| p=0.7 | 0.7          | 0.12         | 1.413591e-09 | 1.696309e-10 | 2.212241e-08 | \n",
       "| p=0.8 | 0.8          | 0.12         | 1.325743e-19 | 1.590892e-20 | 2.074760e-18 | \n",
       "| p=0.9 | 0.9          | 0.12         | 4.175768e-40 | 5.010921e-41 | 6.534989e-39 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "      Models Priors Liklihood    Product      Posterior   \n",
       "p=0.3 0.3    0.12   6.762257e-06 8.114709e-07 1.058279e-04\n",
       "p=0.4 0.4    0.12   1.659816e-02 1.991780e-03 2.597578e-01\n",
       "p=0.5 0.5    0.12   4.669402e-02 5.603283e-03 7.307517e-01\n",
       "p=0.6 0.6    0.25   2.878376e-04 7.195939e-05 9.384579e-03\n",
       "p=0.7 0.7    0.12   1.413591e-09 1.696309e-10 2.212241e-08\n",
       "p=0.8 0.8    0.12   1.325743e-19 1.590892e-20 2.074760e-18\n",
       "p=0.9 0.9    0.12   4.175768e-40 5.010921e-41 6.534989e-39"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df$Product = df$Priors*df$Liklihood\n",
    "df$Posterior=df$Product/sum(df$Product)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good check is that the sum of the Posterior probabilities = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "1"
      ],
      "text/latex": [
       "1"
      ],
      "text/markdown": [
       "1"
      ],
      "text/plain": [
       "[1] 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sum(df$Posterior)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good, the Posterior probabilities sum to 1. Now how are these Posterior Probabilities different than our Priors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'ggplot2' was built under R version 3.4.4\""
     ]
    },
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhwAAAIcCAMAAACKIIdOAAAAY1BMVEUAAAAzMzNDbu5NTU1o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\nahMX3gAAAABJRU5ErkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "options(repr.plot.width=4.5, repr.plot.height=4.5)\n",
    "library(reshape)\n",
    "library(ggplot2)\n",
    "\n",
    "df.long=melt(df, id=\"Models\")\n",
    "\n",
    "plt.std=plt.std=theme(legend.position=\"top\", legend.text = element_text(size=12), axis.text.x = element_text(size=12),  axis.text.y = element_text(size=12), axis.title.y = element_text(size=14), strip.text.x = element_text(size=16), panel.background = element_rect(fill='white', colour='black'), legend.key = element_blank())\n",
    "color1=c(\"royalblue2\", \"red2\")\n",
    "ggplot(data=subset(df.long, variable%in% c(\"Priors\", \"Posterior\")), aes(x=as.factor(Models), y=value, fill=variable))+geom_bar(stat=\"identity\", position=\"dodge\")+ylab(\"Probability\")+scale_fill_manual(values=color1, name=\"\")+xlab(\"Models\")+ggtitle(\"Probabilities after 1st Survey\")+plt.std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Origninally, the prior probabilities are more equally distributed across our models. But, with our beliefs and the survey data we see that it is far more likely the survey results came from a model where the proportion of town attandance is 0.5. \n",
    "\n",
    "This updates our probabilities and we would suggest the town manager order enough food for roughly 50% of Austin. $\\textbf{Now she is more confident that the attendance will be near 50%, when earlier she thought it was more likely that the attendance could be 60%.}$ She is now able to save money and not waste food. What a good reason to employ Bayes' Theorem!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're happy with these results, but suppose we wanted to send another survey closer to the concert date to give us a better estimate of the attendance. We would simply take the \"Posteriors\" from the results above and use them as our \"Priors\" in the calculations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>Models</th><th scope=col>Priors2</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>p=0.3</th><td>0.3         </td><td>1.058279e-04</td></tr>\n",
       "\t<tr><th scope=row>p=0.4</th><td>0.4         </td><td>2.597578e-01</td></tr>\n",
       "\t<tr><th scope=row>p=0.5</th><td>0.5         </td><td>7.307517e-01</td></tr>\n",
       "\t<tr><th scope=row>p=0.6</th><td>0.6         </td><td>9.384579e-03</td></tr>\n",
       "\t<tr><th scope=row>p=0.7</th><td>0.7         </td><td>2.212241e-08</td></tr>\n",
       "\t<tr><th scope=row>p=0.8</th><td>0.8         </td><td>2.074760e-18</td></tr>\n",
       "\t<tr><th scope=row>p=0.9</th><td>0.9         </td><td>6.534989e-39</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       "  & Models & Priors2\\\\\n",
       "\\hline\n",
       "\tp=0.3 & 0.3          & 1.058279e-04\\\\\n",
       "\tp=0.4 & 0.4          & 2.597578e-01\\\\\n",
       "\tp=0.5 & 0.5          & 7.307517e-01\\\\\n",
       "\tp=0.6 & 0.6          & 9.384579e-03\\\\\n",
       "\tp=0.7 & 0.7          & 2.212241e-08\\\\\n",
       "\tp=0.8 & 0.8          & 2.074760e-18\\\\\n",
       "\tp=0.9 & 0.9          & 6.534989e-39\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | Models | Priors2 | \n",
       "|---|---|---|---|---|---|---|\n",
       "| p=0.3 | 0.3          | 1.058279e-04 | \n",
       "| p=0.4 | 0.4          | 2.597578e-01 | \n",
       "| p=0.5 | 0.5          | 7.307517e-01 | \n",
       "| p=0.6 | 0.6          | 9.384579e-03 | \n",
       "| p=0.7 | 0.7          | 2.212241e-08 | \n",
       "| p=0.8 | 0.8          | 2.074760e-18 | \n",
       "| p=0.9 | 0.9          | 6.534989e-39 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "      Models Priors2     \n",
       "p=0.3 0.3    1.058279e-04\n",
       "p=0.4 0.4    2.597578e-01\n",
       "p=0.5 0.5    7.307517e-01\n",
       "p=0.6 0.6    9.384579e-03\n",
       "p=0.7 0.7    2.212241e-08\n",
       "p=0.8 0.8    2.074760e-18\n",
       "p=0.9 0.9    6.534989e-39"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df2=df[c(\"Models\", \"Posterior\")]\n",
    "colnames(df2)[2]=\"Priors2\"\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate the Liklihoods next based on the new survey results.\n",
    "Our new survey was sent to 100 people and 55 responded 'yes'. We calculate a new Liklihood for each model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>Models</th><th scope=col>Priors2</th><th scope=col>Liklihood2</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>p=0.3</th><td>0.3         </td><td>1.058279e-04</td><td>4.273205e-13</td></tr>\n",
       "\t<tr><th scope=row>p=0.4</th><td>0.4         </td><td>2.597578e-01</td><td>2.562323e-07</td></tr>\n",
       "\t<tr><th scope=row>p=0.5</th><td>0.5         </td><td>7.307517e-01</td><td>8.638557e-04</td></tr>\n",
       "\t<tr><th scope=row>p=0.6</th><td>0.6         </td><td>9.384579e-03</td><td>4.913282e-02</td></tr>\n",
       "\t<tr><th scope=row>p=0.7</th><td>0.7         </td><td>2.212241e-08</td><td>4.677968e-02</td></tr>\n",
       "\t<tr><th scope=row>p=0.8</th><td>0.8         </td><td>2.074760e-18</td><td>1.889469e-04</td></tr>\n",
       "\t<tr><th scope=row>p=0.9</th><td>0.9         </td><td>6.534989e-39</td><td>1.161994e-11</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lll}\n",
       "  & Models & Priors2 & Liklihood2\\\\\n",
       "\\hline\n",
       "\tp=0.3 & 0.3          & 1.058279e-04 & 4.273205e-13\\\\\n",
       "\tp=0.4 & 0.4          & 2.597578e-01 & 2.562323e-07\\\\\n",
       "\tp=0.5 & 0.5          & 7.307517e-01 & 8.638557e-04\\\\\n",
       "\tp=0.6 & 0.6          & 9.384579e-03 & 4.913282e-02\\\\\n",
       "\tp=0.7 & 0.7          & 2.212241e-08 & 4.677968e-02\\\\\n",
       "\tp=0.8 & 0.8          & 2.074760e-18 & 1.889469e-04\\\\\n",
       "\tp=0.9 & 0.9          & 6.534989e-39 & 1.161994e-11\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | Models | Priors2 | Liklihood2 | \n",
       "|---|---|---|---|---|---|---|\n",
       "| p=0.3 | 0.3          | 1.058279e-04 | 4.273205e-13 | \n",
       "| p=0.4 | 0.4          | 2.597578e-01 | 2.562323e-07 | \n",
       "| p=0.5 | 0.5          | 7.307517e-01 | 8.638557e-04 | \n",
       "| p=0.6 | 0.6          | 9.384579e-03 | 4.913282e-02 | \n",
       "| p=0.7 | 0.7          | 2.212241e-08 | 4.677968e-02 | \n",
       "| p=0.8 | 0.8          | 2.074760e-18 | 1.889469e-04 | \n",
       "| p=0.9 | 0.9          | 6.534989e-39 | 1.161994e-11 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "      Models Priors2      Liklihood2  \n",
       "p=0.3 0.3    1.058279e-04 4.273205e-13\n",
       "p=0.4 0.4    2.597578e-01 2.562323e-07\n",
       "p=0.5 0.5    7.307517e-01 8.638557e-04\n",
       "p=0.6 0.6    9.384579e-03 4.913282e-02\n",
       "p=0.7 0.7    2.212241e-08 4.677968e-02\n",
       "p=0.8 0.8    2.074760e-18 1.889469e-04\n",
       "p=0.9 0.9    6.534989e-39 1.161994e-11"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df2$Liklihood2=dbinom(65, size=100, prob=Models)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Now we recalculate the product and Posterior proabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>Models</th><th scope=col>Priors2</th><th scope=col>Liklihood2</th><th scope=col>Product2</th><th scope=col>Posterior2</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>p=0.3</th><td>0.3         </td><td>1.058279e-04</td><td>4.273205e-13</td><td>4.522244e-17</td><td>4.139647e-14</td></tr>\n",
       "\t<tr><th scope=row>p=0.4</th><td>0.4         </td><td>2.597578e-01</td><td>2.562323e-07</td><td>6.655836e-08</td><td>6.092730e-05</td></tr>\n",
       "\t<tr><th scope=row>p=0.5</th><td>0.5         </td><td>7.307517e-01</td><td>8.638557e-04</td><td>6.312640e-04</td><td>5.778570e-01</td></tr>\n",
       "\t<tr><th scope=row>p=0.6</th><td>0.6         </td><td>9.384579e-03</td><td>4.913282e-02</td><td>4.610909e-04</td><td>4.220811e-01</td></tr>\n",
       "\t<tr><th scope=row>p=0.7</th><td>0.7         </td><td>2.212241e-08</td><td>4.677968e-02</td><td>1.034879e-09</td><td>9.473250e-07</td></tr>\n",
       "\t<tr><th scope=row>p=0.8</th><td>0.8         </td><td>2.074760e-18</td><td>1.889469e-04</td><td>3.920195e-22</td><td>3.588534e-19</td></tr>\n",
       "\t<tr><th scope=row>p=0.9</th><td>0.9         </td><td>6.534989e-39</td><td>1.161994e-11</td><td>7.593618e-50</td><td>6.951173e-47</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllll}\n",
       "  & Models & Priors2 & Liklihood2 & Product2 & Posterior2\\\\\n",
       "\\hline\n",
       "\tp=0.3 & 0.3          & 1.058279e-04 & 4.273205e-13 & 4.522244e-17 & 4.139647e-14\\\\\n",
       "\tp=0.4 & 0.4          & 2.597578e-01 & 2.562323e-07 & 6.655836e-08 & 6.092730e-05\\\\\n",
       "\tp=0.5 & 0.5          & 7.307517e-01 & 8.638557e-04 & 6.312640e-04 & 5.778570e-01\\\\\n",
       "\tp=0.6 & 0.6          & 9.384579e-03 & 4.913282e-02 & 4.610909e-04 & 4.220811e-01\\\\\n",
       "\tp=0.7 & 0.7          & 2.212241e-08 & 4.677968e-02 & 1.034879e-09 & 9.473250e-07\\\\\n",
       "\tp=0.8 & 0.8          & 2.074760e-18 & 1.889469e-04 & 3.920195e-22 & 3.588534e-19\\\\\n",
       "\tp=0.9 & 0.9          & 6.534989e-39 & 1.161994e-11 & 7.593618e-50 & 6.951173e-47\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | Models | Priors2 | Liklihood2 | Product2 | Posterior2 | \n",
       "|---|---|---|---|---|---|---|\n",
       "| p=0.3 | 0.3          | 1.058279e-04 | 4.273205e-13 | 4.522244e-17 | 4.139647e-14 | \n",
       "| p=0.4 | 0.4          | 2.597578e-01 | 2.562323e-07 | 6.655836e-08 | 6.092730e-05 | \n",
       "| p=0.5 | 0.5          | 7.307517e-01 | 8.638557e-04 | 6.312640e-04 | 5.778570e-01 | \n",
       "| p=0.6 | 0.6          | 9.384579e-03 | 4.913282e-02 | 4.610909e-04 | 4.220811e-01 | \n",
       "| p=0.7 | 0.7          | 2.212241e-08 | 4.677968e-02 | 1.034879e-09 | 9.473250e-07 | \n",
       "| p=0.8 | 0.8          | 2.074760e-18 | 1.889469e-04 | 3.920195e-22 | 3.588534e-19 | \n",
       "| p=0.9 | 0.9          | 6.534989e-39 | 1.161994e-11 | 7.593618e-50 | 6.951173e-47 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "      Models Priors2      Liklihood2   Product2     Posterior2  \n",
       "p=0.3 0.3    1.058279e-04 4.273205e-13 4.522244e-17 4.139647e-14\n",
       "p=0.4 0.4    2.597578e-01 2.562323e-07 6.655836e-08 6.092730e-05\n",
       "p=0.5 0.5    7.307517e-01 8.638557e-04 6.312640e-04 5.778570e-01\n",
       "p=0.6 0.6    9.384579e-03 4.913282e-02 4.610909e-04 4.220811e-01\n",
       "p=0.7 0.7    2.212241e-08 4.677968e-02 1.034879e-09 9.473250e-07\n",
       "p=0.8 0.8    2.074760e-18 1.889469e-04 3.920195e-22 3.588534e-19\n",
       "p=0.9 0.9    6.534989e-39 1.161994e-11 7.593618e-50 6.951173e-47"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df2$Product2 = df2$Priors*df2$Liklihood2\n",
    "df2$Posterior2=df2$Product2/sum(df2$Product2)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhwAAAIcCAMAAACKIIdOAAAAY1BMVEUAAAAzMzNDbu5NTU1o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\neIF3AWS8wLsAMl7gXQAZL/AugIyX/wc9UR9nG0QC3gAAAABJRU5ErkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.long2=melt(df2, id=\"Models\")\n",
    "\n",
    "ggplot(data=subset(df.long2, variable%in% c(\"Priors2\", \"Posterior2\")), aes(x=as.factor(Models), y=value, fill=variable))+geom_bar(stat=\"identity\", position=\"dodge\")+plt.std+ylab(\"Probability\")+scale_fill_manual(values=color1, name=\"\")+xlab(\"Models\")+ggtitle(\"Probabilities after 2nd Survey\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, after the 2nd survey we are still confident the proprotion of Austin attending the concert will be 50%, but there is also a roughly 42% chance that p=0.6. If we repeated this again and again and survey results came from a known distribution, we would converge on the true probabilities for each model.\n",
    "\n",
    "We'd like to be a bit more confident before placing our food order. But, we don't have time for more surveys. We have some statistic nerds in the city planning group, and they suggest running simulations to approximate survey results and update our Posterior probabilities.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the same general idea as above, we'll construct our Posterior distribution based on the Prior distribution. If these two distributions are in the same family they are called $conjugates$. \n",
    "\n",
    "For the binomial distribution (our survey successes or failures), the conjugate is a beta distribution. Thus, when we know the Prior distribution we can determine the Posterior distribution, which is proportional to the Likelihood x Prior distribution. This helps simplify our ability to calculate the Posterior. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Posterior = \\frac{(Likelihood) * Prior}{Data}$ \n",
    "\n",
    "$P(A|B) = \\frac{P(B|A) P(A)}{P(B)}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the denominator is a normalizing term (makes the probabilities sum to 1), we know that Posterior is proportional to Likelihood and Prior.  Think of this like chemistry with conjugate acids and bases. If we know 1, we can determine the other one we need to nuetralize our chemicals. .\n",
    "\n",
    "\n",
    "In this binomial example:\n",
    "\n",
    "$Posterior Binomial = {(Binomial  Likelihood) * Beta Prior}$\n",
    "\n",
    "We won't get into all the details of a Beta distribution, but think of it like a normal distribution and instead of being characterizied by the mean and standard deviation, it is paramaterized by two shape terms a and b."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, instead of using survey results we are going to use our knowledge to create a Prior distribution where we believe the true town attendance is approximated by a Beta curve with shape parameters a= and b=\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abprior="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rnorm(n=100, mean=0.6, sd=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markov Chain Monte Carlo\n",
    "To better approximate our Posterior distribution with simulated surveys, we will use a Markov Chain Monte Carlo simulation, or MCMC for short. We won't get into all the details here, but the main goal of a MCMC is to simulate the Posterior distribution instead of solving for it analytically (which can be very difficult).\n",
    "\n",
    "This basically simulates random draws from a target distribution (Posterior distribution), and then the frequency of these draws is summarized as the probability of each model being true.\n",
    "\n",
    "#### A Markov Chain creates a sequence of numbers, where each value depends only on the value prior and does not have a 'memory'.\n",
    "\n",
    "#### A Monte Carlo simulation generates random numbers from some distribution, and if we repeat this enough, the estimate will converge on the actual value.\n",
    "\n",
    "If we put these two things together, we are creating random draws of Markov Chains. These chains (or vectors of values) represent the Posterior distribution. Since we have many many Markov Chains (thanks to Monte Carlo simulations) the simulated Posterior distribution approaches the true distribution, and we are able to calculate the probabilities of each 'model' being true given the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we are trying to calculate the true proportion of people in Austin that will attend this concert. The stats nerds have looked at previous attendance records, they determine:\n",
    "\n",
    "1. Prior attendance median value of 0.60\n",
    "2. The Attendance proportion follows a beta distribution with a=2.9 and b=2.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metropolis-Hastings\n",
    "\n",
    "This algorithm uses a candidate or proposal distribution, say q(Â·, Î½), where Î½ is/are parameters that is/are fixed by the user - called tuning parameters. As we outline in\n",
    "the next page, the MH algorithm constructs a Markov Chain by proposing a value for Î¸ from this candidate distribution, and then either accepting or rejecting this value (with a certain probability). Theoretically the proposal distribution can be any distribution, but in practice you choose something really simple: a Normal distribution if your parameter\n",
    "can be any real number.\n",
    "\n",
    "Assume x(t) follows normal distribution with mean=0.6 and sd=.2\n",
    "\n",
    "https://link.springer.com/content/pdf/10.1007%2F978-1-4419-1576-4_6.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>0.882041065604202</li>\n",
       "\t<li>0.274276840415855</li>\n",
       "\t<li>0.880155024679999</li>\n",
       "\t<li>0.586239129696415</li>\n",
       "\t<li>0.747116844648599</li>\n",
       "\t<li>0.53573203846275</li>\n",
       "\t<li>0.295568296516703</li>\n",
       "\t<li>0.448928266362921</li>\n",
       "\t<li>0.354975871917517</li>\n",
       "\t<li>0.583164252106381</li>\n",
       "\t<li>0.875353247163838</li>\n",
       "\t<li>0.531571406801782</li>\n",
       "\t<li>0.653140648922936</li>\n",
       "\t<li>0.76996773257856</li>\n",
       "\t<li>0.49639949591029</li>\n",
       "\t<li>0.70251526517922</li>\n",
       "\t<li>0.907285142159746</li>\n",
       "\t<li>0.864000394287678</li>\n",
       "\t<li>0.858354615339066</li>\n",
       "\t<li>0.692952630063978</li>\n",
       "\t<li>0.32108568315467</li>\n",
       "\t<li>0.2627687284742</li>\n",
       "\t<li>0.240100197478769</li>\n",
       "\t<li>0.669714098200247</li>\n",
       "\t<li>0.077220129141343</li>\n",
       "\t<li>0.184493981661047</li>\n",
       "\t<li>0.508616445174731</li>\n",
       "\t<li>0.356945738653017</li>\n",
       "\t<li>0.521910469644742</li>\n",
       "\t<li>0.647516350079766</li>\n",
       "\t<li>0.803745709001954</li>\n",
       "\t<li>1.01764334806512</li>\n",
       "\t<li>0.343411119447338</li>\n",
       "\t<li>0.414668554515635</li>\n",
       "\t<li>0.765335310821583</li>\n",
       "\t<li>0.791088592754366</li>\n",
       "\t<li>0.509474604620295</li>\n",
       "\t<li>0.61278157020973</li>\n",
       "\t<li>0.460024940371651</li>\n",
       "\t<li>0.514704809767976</li>\n",
       "\t<li>0.64037042173561</li>\n",
       "\t<li>0.623831723330652</li>\n",
       "\t<li>0.449386165828117</li>\n",
       "\t<li>0.653850316962059</li>\n",
       "\t<li>0.143393945347952</li>\n",
       "\t<li>0.538305005976511</li>\n",
       "\t<li>0.563368369668136</li>\n",
       "\t<li>0.18321642829517</li>\n",
       "\t<li>0.673634348722145</li>\n",
       "\t<li>0.857231787359435</li>\n",
       "\t<li>0.886548269858155</li>\n",
       "\t<li>0.736342357122816</li>\n",
       "\t<li>0.838854376967487</li>\n",
       "\t<li>0.734576162745537</li>\n",
       "\t<li>0.431707486825568</li>\n",
       "\t<li>0.375304981572382</li>\n",
       "\t<li>0.77803018889383</li>\n",
       "\t<li>0.656990126006069</li>\n",
       "\t<li>0.679241511393037</li>\n",
       "\t<li>0.687369909746366</li>\n",
       "\t<li>0.366180709196916</li>\n",
       "\t<li>0.499255811316547</li>\n",
       "\t<li>0.898701671890555</li>\n",
       "\t<li>0.686292446742887</li>\n",
       "\t<li>0.792088542982585</li>\n",
       "\t<li>0.705244551882658</li>\n",
       "\t<li>0.371569548391854</li>\n",
       "\t<li>1.0380764732634</li>\n",
       "\t<li>0.345628245172933</li>\n",
       "\t<li>0.823555667115394</li>\n",
       "\t<li>0.837521029227115</li>\n",
       "\t<li>0.660320644067207</li>\n",
       "\t<li>0.318827357239243</li>\n",
       "\t<li>1.17872308044941</li>\n",
       "\t<li>0.842757339366994</li>\n",
       "\t<li>0.761504240104473</li>\n",
       "\t<li>0.900743998182818</li>\n",
       "\t<li>0.719045793983062</li>\n",
       "\t<li>0.491958327591917</li>\n",
       "\t<li>0.434700202028922</li>\n",
       "\t<li>0.655964846633329</li>\n",
       "\t<li>0.618110891785479</li>\n",
       "\t<li>0.628082905248983</li>\n",
       "\t<li>0.506120832385581</li>\n",
       "\t<li>0.570295837661017</li>\n",
       "\t<li>0.758874517866424</li>\n",
       "\t<li>0.386038785693373</li>\n",
       "\t<li>0.410654840651322</li>\n",
       "\t<li>0.621135552459095</li>\n",
       "\t<li>0.616851940517507</li>\n",
       "\t<li>0.661935971076873</li>\n",
       "\t<li>0.731395210962271</li>\n",
       "\t<li>0.61456344710347</li>\n",
       "\t<li>0.489899390977779</li>\n",
       "\t<li>0.532425911592434</li>\n",
       "\t<li>0.332691990959905</li>\n",
       "\t<li>0.354896188643606</li>\n",
       "\t<li>0.793370741414344</li>\n",
       "\t<li>0.618952731174238</li>\n",
       "\t<li>0.72384363246048</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 0.882041065604202\n",
       "\\item 0.274276840415855\n",
       "\\item 0.880155024679999\n",
       "\\item 0.586239129696415\n",
       "\\item 0.747116844648599\n",
       "\\item 0.53573203846275\n",
       "\\item 0.295568296516703\n",
       "\\item 0.448928266362921\n",
       "\\item 0.354975871917517\n",
       "\\item 0.583164252106381\n",
       "\\item 0.875353247163838\n",
       "\\item 0.531571406801782\n",
       "\\item 0.653140648922936\n",
       "\\item 0.76996773257856\n",
       "\\item 0.49639949591029\n",
       "\\item 0.70251526517922\n",
       "\\item 0.907285142159746\n",
       "\\item 0.864000394287678\n",
       "\\item 0.858354615339066\n",
       "\\item 0.692952630063978\n",
       "\\item 0.32108568315467\n",
       "\\item 0.2627687284742\n",
       "\\item 0.240100197478769\n",
       "\\item 0.669714098200247\n",
       "\\item 0.077220129141343\n",
       "\\item 0.184493981661047\n",
       "\\item 0.508616445174731\n",
       "\\item 0.356945738653017\n",
       "\\item 0.521910469644742\n",
       "\\item 0.647516350079766\n",
       "\\item 0.803745709001954\n",
       "\\item 1.01764334806512\n",
       "\\item 0.343411119447338\n",
       "\\item 0.414668554515635\n",
       "\\item 0.765335310821583\n",
       "\\item 0.791088592754366\n",
       "\\item 0.509474604620295\n",
       "\\item 0.61278157020973\n",
       "\\item 0.460024940371651\n",
       "\\item 0.514704809767976\n",
       "\\item 0.64037042173561\n",
       "\\item 0.623831723330652\n",
       "\\item 0.449386165828117\n",
       "\\item 0.653850316962059\n",
       "\\item 0.143393945347952\n",
       "\\item 0.538305005976511\n",
       "\\item 0.563368369668136\n",
       "\\item 0.18321642829517\n",
       "\\item 0.673634348722145\n",
       "\\item 0.857231787359435\n",
       "\\item 0.886548269858155\n",
       "\\item 0.736342357122816\n",
       "\\item 0.838854376967487\n",
       "\\item 0.734576162745537\n",
       "\\item 0.431707486825568\n",
       "\\item 0.375304981572382\n",
       "\\item 0.77803018889383\n",
       "\\item 0.656990126006069\n",
       "\\item 0.679241511393037\n",
       "\\item 0.687369909746366\n",
       "\\item 0.366180709196916\n",
       "\\item 0.499255811316547\n",
       "\\item 0.898701671890555\n",
       "\\item 0.686292446742887\n",
       "\\item 0.792088542982585\n",
       "\\item 0.705244551882658\n",
       "\\item 0.371569548391854\n",
       "\\item 1.0380764732634\n",
       "\\item 0.345628245172933\n",
       "\\item 0.823555667115394\n",
       "\\item 0.837521029227115\n",
       "\\item 0.660320644067207\n",
       "\\item 0.318827357239243\n",
       "\\item 1.17872308044941\n",
       "\\item 0.842757339366994\n",
       "\\item 0.761504240104473\n",
       "\\item 0.900743998182818\n",
       "\\item 0.719045793983062\n",
       "\\item 0.491958327591917\n",
       "\\item 0.434700202028922\n",
       "\\item 0.655964846633329\n",
       "\\item 0.618110891785479\n",
       "\\item 0.628082905248983\n",
       "\\item 0.506120832385581\n",
       "\\item 0.570295837661017\n",
       "\\item 0.758874517866424\n",
       "\\item 0.386038785693373\n",
       "\\item 0.410654840651322\n",
       "\\item 0.621135552459095\n",
       "\\item 0.616851940517507\n",
       "\\item 0.661935971076873\n",
       "\\item 0.731395210962271\n",
       "\\item 0.61456344710347\n",
       "\\item 0.489899390977779\n",
       "\\item 0.532425911592434\n",
       "\\item 0.332691990959905\n",
       "\\item 0.354896188643606\n",
       "\\item 0.793370741414344\n",
       "\\item 0.618952731174238\n",
       "\\item 0.72384363246048\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 0.882041065604202\n",
       "2. 0.274276840415855\n",
       "3. 0.880155024679999\n",
       "4. 0.586239129696415\n",
       "5. 0.747116844648599\n",
       "6. 0.53573203846275\n",
       "7. 0.295568296516703\n",
       "8. 0.448928266362921\n",
       "9. 0.354975871917517\n",
       "10. 0.583164252106381\n",
       "11. 0.875353247163838\n",
       "12. 0.531571406801782\n",
       "13. 0.653140648922936\n",
       "14. 0.76996773257856\n",
       "15. 0.49639949591029\n",
       "16. 0.70251526517922\n",
       "17. 0.907285142159746\n",
       "18. 0.864000394287678\n",
       "19. 0.858354615339066\n",
       "20. 0.692952630063978\n",
       "21. 0.32108568315467\n",
       "22. 0.2627687284742\n",
       "23. 0.240100197478769\n",
       "24. 0.669714098200247\n",
       "25. 0.077220129141343\n",
       "26. 0.184493981661047\n",
       "27. 0.508616445174731\n",
       "28. 0.356945738653017\n",
       "29. 0.521910469644742\n",
       "30. 0.647516350079766\n",
       "31. 0.803745709001954\n",
       "32. 1.01764334806512\n",
       "33. 0.343411119447338\n",
       "34. 0.414668554515635\n",
       "35. 0.765335310821583\n",
       "36. 0.791088592754366\n",
       "37. 0.509474604620295\n",
       "38. 0.61278157020973\n",
       "39. 0.460024940371651\n",
       "40. 0.514704809767976\n",
       "41. 0.64037042173561\n",
       "42. 0.623831723330652\n",
       "43. 0.449386165828117\n",
       "44. 0.653850316962059\n",
       "45. 0.143393945347952\n",
       "46. 0.538305005976511\n",
       "47. 0.563368369668136\n",
       "48. 0.18321642829517\n",
       "49. 0.673634348722145\n",
       "50. 0.857231787359435\n",
       "51. 0.886548269858155\n",
       "52. 0.736342357122816\n",
       "53. 0.838854376967487\n",
       "54. 0.734576162745537\n",
       "55. 0.431707486825568\n",
       "56. 0.375304981572382\n",
       "57. 0.77803018889383\n",
       "58. 0.656990126006069\n",
       "59. 0.679241511393037\n",
       "60. 0.687369909746366\n",
       "61. 0.366180709196916\n",
       "62. 0.499255811316547\n",
       "63. 0.898701671890555\n",
       "64. 0.686292446742887\n",
       "65. 0.792088542982585\n",
       "66. 0.705244551882658\n",
       "67. 0.371569548391854\n",
       "68. 1.0380764732634\n",
       "69. 0.345628245172933\n",
       "70. 0.823555667115394\n",
       "71. 0.837521029227115\n",
       "72. 0.660320644067207\n",
       "73. 0.318827357239243\n",
       "74. 1.17872308044941\n",
       "75. 0.842757339366994\n",
       "76. 0.761504240104473\n",
       "77. 0.900743998182818\n",
       "78. 0.719045793983062\n",
       "79. 0.491958327591917\n",
       "80. 0.434700202028922\n",
       "81. 0.655964846633329\n",
       "82. 0.618110891785479\n",
       "83. 0.628082905248983\n",
       "84. 0.506120832385581\n",
       "85. 0.570295837661017\n",
       "86. 0.758874517866424\n",
       "87. 0.386038785693373\n",
       "88. 0.410654840651322\n",
       "89. 0.621135552459095\n",
       "90. 0.616851940517507\n",
       "91. 0.661935971076873\n",
       "92. 0.731395210962271\n",
       "93. 0.61456344710347\n",
       "94. 0.489899390977779\n",
       "95. 0.532425911592434\n",
       "96. 0.332691990959905\n",
       "97. 0.354896188643606\n",
       "98. 0.793370741414344\n",
       "99. 0.618952731174238\n",
       "100. 0.72384363246048\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  [1] 0.88204107 0.27427684 0.88015502 0.58623913 0.74711684 0.53573204\n",
       "  [7] 0.29556830 0.44892827 0.35497587 0.58316425 0.87535325 0.53157141\n",
       " [13] 0.65314065 0.76996773 0.49639950 0.70251527 0.90728514 0.86400039\n",
       " [19] 0.85835462 0.69295263 0.32108568 0.26276873 0.24010020 0.66971410\n",
       " [25] 0.07722013 0.18449398 0.50861645 0.35694574 0.52191047 0.64751635\n",
       " [31] 0.80374571 1.01764335 0.34341112 0.41466855 0.76533531 0.79108859\n",
       " [37] 0.50947460 0.61278157 0.46002494 0.51470481 0.64037042 0.62383172\n",
       " [43] 0.44938617 0.65385032 0.14339395 0.53830501 0.56336837 0.18321643\n",
       " [49] 0.67363435 0.85723179 0.88654827 0.73634236 0.83885438 0.73457616\n",
       " [55] 0.43170749 0.37530498 0.77803019 0.65699013 0.67924151 0.68736991\n",
       " [61] 0.36618071 0.49925581 0.89870167 0.68629245 0.79208854 0.70524455\n",
       " [67] 0.37156955 1.03807647 0.34562825 0.82355567 0.83752103 0.66032064\n",
       " [73] 0.31882736 1.17872308 0.84275734 0.76150424 0.90074400 0.71904579\n",
       " [79] 0.49195833 0.43470020 0.65596485 0.61811089 0.62808291 0.50612083\n",
       " [85] 0.57029584 0.75887452 0.38603879 0.41065484 0.62113555 0.61685194\n",
       " [91] 0.66193597 0.73139521 0.61456345 0.48989939 0.53242591 0.33269199\n",
       " [97] 0.35489619 0.79337074 0.61895273 0.72384363"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'dplyr' was built under R version 3.4.4\""
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error: package or namespace load failed for 'dplyr' in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()), versionCheck = vI[[j]]):\n namespace 'R6' 2.2.1 is being loaded, but >= 2.2.2 is required\n",
     "output_type": "error",
     "traceback": [
      "Error: package or namespace load failed for 'dplyr' in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()), versionCheck = vI[[j]]):\n namespace 'R6' 2.2.1 is being loaded, but >= 2.2.2 is required\nTraceback:\n",
      "1. library(dplyr)",
      "2. tryCatch({\n .     attr(package, \"LibPath\") <- which.lib.loc\n .     ns <- loadNamespace(package, lib.loc)\n .     env <- attachNamespace(ns, pos = pos, deps)\n . }, error = function(e) {\n .     P <- if (!is.null(cc <- conditionCall(e))) \n .         paste(\" in\", deparse(cc)[1L])\n .     else \"\"\n .     msg <- gettextf(\"package or namespace load failed for %s%s:\\n %s\", \n .         sQuote(package), P, conditionMessage(e))\n .     if (logical.return) \n .         message(paste(\"Error:\", msg), domain = NA)\n .     else stop(msg, call. = FALSE, domain = NA)\n . })",
      "3. tryCatchList(expr, classes, parentenv, handlers)",
      "4. tryCatchOne(expr, names, parentenv, handlers[[1L]])",
      "5. value[[3L]](cond)",
      "6. stop(msg, call. = FALSE, domain = NA)"
     ]
    }
   ],
   "source": [
    "library(dplyr)\n",
    "library(TeachBayes)\n",
    "beta_draw(c(2.9,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhwAAAIcCAMAAACKIIdOAAAAMFBMVEUAAABNTU1oaGh8fHyM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\nRU5ErkJggg==",
      "text/plain": [
       "Plot with title \"Histogram of samp\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tuneSD=1.5\n",
    "\n",
    "M=2000\n",
    "samp=1:M\n",
    "counter=0\n",
    "\n",
    "#starting value\n",
    "samp[1]=1.2\n",
    "\n",
    "for (m in 2:M)\n",
    "{\n",
    "samp[m]=samp[m-1] #default if not changed below\n",
    "candidate=rnorm(1,samp[m-1],tuneSD) #note symmetry\n",
    "ll.cur=dnorm(samp[m-1],0,1,log=T)\n",
    "ll.cand=dnorm(candidate,0,1,log=T)\n",
    "prob=min(exp(ll.cand-ll.cur),1)\n",
    "coin=rbinom(1,1,prob)\n",
    "if (coin)\n",
    "{\n",
    "samp[m]=candidate\n",
    "counter=counter+1\n",
    "}\n",
    "}\n",
    "\n",
    "accept.rate=sum(counter)/M\n",
    "hist(samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>53</li>\n",
       "\t<li>61</li>\n",
       "\t<li>55</li>\n",
       "\t<li>46</li>\n",
       "\t<li>44</li>\n",
       "\t<li>50</li>\n",
       "\t<li>59</li>\n",
       "\t<li>46</li>\n",
       "\t<li>44</li>\n",
       "\t<li>50</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 53\n",
       "\\item 61\n",
       "\\item 55\n",
       "\\item 46\n",
       "\\item 44\n",
       "\\item 50\n",
       "\\item 59\n",
       "\\item 46\n",
       "\\item 44\n",
       "\\item 50\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 53\n",
       "2. 61\n",
       "3. 55\n",
       "4. 46\n",
       "5. 44\n",
       "6. 50\n",
       "7. 59\n",
       "8. 46\n",
       "9. 44\n",
       "10. 50\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] 53 61 55 46 44 50 59 46 44 50"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rbinom(n=10, size=100,prob=0.5) \n",
    "#n = number of draws, size = sample size of population, prob = probability of success (or attendance in this case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### A Monte Carlo simulation generates random numbers from some distribution, and if we repeat this enough, the estimate will converge on the actual value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why do we need the Priors are all, you may ask? Well, they help constrain our estimates. If we had no Priors, the Likelihood of observing each model ${given}$ the survey results, would be based soley on the survey results (yes and no responses for a binomial) and give no weight to the fact that usually 60% and 70% of the population attends a concert. Without these priors our estimated proportion of the town in attendance would be:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Monte Carlo methods are simulations instead of analytical solutions. In frequentist (or the more traditional) statistics, you would use a function to maximize a likelihood. Here we simulate results and determine which results would occur in greatest frequency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of times we have some knowledge or beliefs about something, and then we collect evidence and update our beliefs. This is the basic scientific method, and also sums up Baye's theory.\n",
    "\n",
    "Instead of knowing absolute probabilities of an event, we use the information we have at hand and our prior belief of the situation to update our belief (now called a posterior).\n",
    "\n",
    "Let's explore how Bayes makes use of these prior beliefs to help us better estimate things are are interested in.\n",
    "\n",
    "For example, we want to know the average height of women in the U.S. We have know prior knowledge in the area, so we assume that heights can be any positive value. We sample 10 women and the mean and standard devations of heights (in decimal feet 5.5 = 5'6\") are:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "package 'ggplot2' successfully unpacked and MD5 sums checked\n",
      "package 'dplyr' successfully unpacked and MD5 sums checked\n",
      "package 'sciplot' successfully unpacked and MD5 sums checked\n",
      "package 'repr' successfully unpacked and MD5 sums checked\n",
      "package 'VennDiagram' successfully unpacked and MD5 sums checked\n",
      "\n",
      "The downloaded binary packages are in\n",
      "\tC:\\Users\\nrb75\\AppData\\Local\\Temp\\RtmpSmnMwB\\downloaded_packages\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "5.39"
      ],
      "text/latex": [
       "5.39"
      ],
      "text/markdown": [
       "5.39"
      ],
      "text/plain": [
       "[1] 5.39"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.341402336775183"
      ],
      "text/latex": [
       "0.341402336775183"
      ],
      "text/markdown": [
       "0.341402336775183"
      ],
      "text/plain": [
       "[1] 0.3414023"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "options(repos = c('https://cloud.r-project.org/'))\n",
    "install.packages(c(\"ggplot2\", \"dplyr\", \"sciplot\", \"repr\", \"VennDiagram\"))\n",
    "\n",
    "heights=c(5,5.2,5.7,5.2,5.8,5.10,5.1,5.3,6.,5.5) #heights in ft decimal feet 5'6\" = 5.5 ft\n",
    "mean.height=mean(heights)\n",
    "sd.height=sd(heights)\n",
    "\n",
    "mean.height\n",
    "round(sd.height,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, whats the probabiity of a certain height given these measurements? We can create a distribution for these heights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "For example, we believe that the average height of women is 5'5\" and that these heights are normally distributed. We collect some data from 10 women, and are now going to check our prior hypothesis and update it to a posterior estimate. We do this by creating a posterior distribution based on our belief the average is 5'5\" and liklihood of that being true based on our collected data.\n",
    "\n",
    "The measured mean height ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the measured standard deviation of height ="
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
